<!DOCTYPE html>
<html lang="en">
<!-- Google tag (gtag.js) -->
<script async src="https://www.googletagmanager.com/gtag/js?id=G-9KJZG728V2"></script>
<script>
  window.dataLayer = window.dataLayer || [];
  function gtag(){dataLayer.push(arguments);}
  gtag('js', new Date());

  gtag('config', 'G-9KJZG728V2');
</script>
<head>
	<meta charset="utf-8">
	<meta name="viewport" content="width=device-width, initial-scale=1.0">
	<meta name="author" content="Sai Nikhil Aratipamula">
	<meta name="description" content="Sai Nikhil Aratipamula personal website">
	<meta http-equiv="Content-Security-Policy"
		content="default-src 'self'; script-src 'none'; object-src 'none'; child-src 'none'; require-trusted-types-for 'script';">
	<title>Sai Nikhil Aratipamula</title>
	<link href="style.css" rel="stylesheet">
	<link href="fontawesome-all.min.css" rel="stylesheet">

</head>

<body>
	<nav>
		<ul id="navigation">
			<li><a href="#about">About</a></li>
			<li><a href="#experience">Experience</a></li>
			<li><a href="#projects">Projects</a></li>
			<li><a href="#skills&certifications">Skills & Certifications</a></li>
			<li><a href="#developments">Developments</a></li>
			<li><a href="data/Sai Nikhil Aratipamula_Resume.pdf" target="_blank">CV</a></li>
			<li><a href="#contact">Contact</a></li>

		</ul>
	</nav>

	<main>
		<section id="about">
    <div class="vertical-center">
        <h2>Hello,</h2>
        <img src="data/professtioanl.jpg" alt="Sai Nikhil Aratipamula">
        <p>
            I'm <a href="#about">Sai Nikhil Aratipamula</a>, a passionate 
            <strong>data professional</strong> üíª who began as a Data Engineer working with structured 
            on-premises data, managing and optimizing traditional data systems. Over time, I transitioned 
            to leveraging cloud platforms ‚òÅÔ∏è, enabling scalable data transformations and modern 
            analytics solutions. 
        </p>

        <p>
            I have designed and implemented robust pipelines üîÑ to process and integrate vast datasets, 
            ensuring seamless data flow and accessibility. Pursuing my Master‚Äôs in Data Science at 
            Florida State University üéì, I have taken a deep dive into 
            <strong>data governance principles</strong> üìú, mastering methodologies for ensuring data quality, 
            security, and compliance.
        </p>

        <p>
            This academic journey has refined my skills in managing the lifecycle of data assets and 
            implementing best practices in data stewardship üîç, empowering me to handle complex datasets 
            with precision and accountability.
        </p>

        <p>
            Beyond engineering solutions, I‚Äôve advanced into developing predictive models üß† and 
            machine learning algorithms, turning raw data into actionable insights üìà. By analyzing 
            trends, patterns, and correlations üîç, I‚Äôve provided businesses with valuable forecasts 
            and strategies, empowering data-driven decision-making.
        </p>

        <p>
            My ability to harness data at every stage‚Äîfrom collection and transformation to modeling 
            and visualization‚Äîhas directly contributed to optimizing operations, enhancing customer 
            experiences, and driving business growth üöÄ.
        </p>

        <p>
            Through a blend of <strong>technical expertise</strong>, <strong>academic insights</strong>, and 
            <strong>practical experience</strong>, I transform raw data into impactful solutions üåü that enable 
            businesses to thrive in data-driven environments.
        </p>

        <p>The best way to connect with me is through 
            <a href="mailto:snaratipamula@gmail.com" target="_blank">email</a>.
        </p>

        <br>

        <p>
            <a href="https://www.linkedin.com/in/sainikhilaratipamula/" target="_blank">
                <span class="fab fa-linkedin-in"></span> LinkedIn: in/Sai Nikhil Aratipamula/
            </a>
            <br>
            <a href="https://github.com/SaiNikhilAratipamula" target="_blank">
                <span class="fab fa-github"></span> GitHub: /Sai Nikhil Aratipamula
            </a>
            <br>
        </p>
    </div>
</section>

		<div class="container">

			<section id="experience">
				<h2> Work Experience</h2>

				<ul>
					<li><strong>Oct 2024 &mdash; Present</strong>, Data Engineering Intern @<a
							href="https://www.consultevergreen.com/" target="_blank">Evergreen Solutions</a>
						<address>
							Tallahassee,
							Florida</address>
						<details>
							<summary>Details</summary>
							<ul>
								<li>Engineered an end-to-end data pipeline using PySpark for compensation analysis, enhancing processing efficiency by 40%.</li>
								<li>Refined data management workflows by implementing Python and SQL techniques, ensuring accuracy and consistency.</li>
								<li>Formulated an Advanced Excel template to automate data ingestion from multiple sources, improving operational efficiency.</li>
								<li>Created interactive Power BI dashboards to deliver actionable insights for executives and clients, enabling data-driven decision-making.</li>
								
								
							</ul>
						</details>
					</li>







			


				
					<li><strong>July 2024 &mdash; Oct 2024</strong>, Research Intern - Data Engineering @<a
							href="https://www.fsu.edu/" target="_blank">LTIMindtree.</a>
						<address>
							Tallahassee,
							Florida</address>
						<details>
							<summary>Details</summary>
							<ul>
								<li>Built and managed ETL pipelines using AWS and GCP to efficiently process and analyze large-scale graph datasets.</li>
								<li>Orchestrated automated workflows using Apache Airflow, Cloud Composer, and AWS Step Functions, reducing processing time by
30% while ensuring scalability and compliance with data governance standards.</li>
								<li>Managed cloud data storage and retrieval with AWS Redshift, DynamoDB, S3, and GCP BigQuery, optimizing query performance and
enabling real-time data insights across terabyte-scale datasets.</li>
								
								
							</ul>
						</details>
					</li>



					<li><strong>August 2022 &mdash; July 2023</strong>, Senior Data Engineer @<a
							href="https://www.ltimindtree.com/" target="_blank">LTIMindtree.</a>
						<address>
							Chennai,
							India</address>
						<details>
							<summary>Details</summary>
							<ul>
								<li>Developed and implemented ETL pipelines using PySpark in Databricks and AWS Glue, resulting in a 50% increase in data processing
efficiency and a 40% improvement in data quality across various structured and unstructured datasets by reducing cloud costs by 30%.</li>
								<li>Constructed and fine-tuned complex SQL queries to extract and transform data from multiple databases, leveraging Python for
automation to minimize manual work and improve operational efficiency by 30%.</li>
								<li>Deployed data workflows and scheduling using Apache Airflow and Shell scripting, reducing manual intervention by 50% and
optimizing pipeline execution, leading to a 30% reduction in processing time.</li>
								<li>Improved data storage and processing capabilities by implementing Hadoop, Hive, and HDFS, enhancing data scalability and
throughput by 40%, ensuring efficient reporting and analytics for stakeholders.</li>
								<li>Collaborated with key stakeholders to gather data requirements, ensuring integrity and accuracy through validation, and quality checks.</li>
								<li>Enhanced data quality and reduced processing time by 30% by resolving issues within the Precertification tool.</li>
								<li>Organized interactive meetings to gather user and functional requirements effectively..</li>
								<li>Resolved data performance and pipeline issues while providing ongoing support and optimizing data systems for improved efficiency.</li>
								
							</ul>
						</details>
					</li>
					<li><strong>June 2022 &mdash; August 2022</strong>, Data Engineer @<a
							href="https://www.ltimindtree.com/" target="_blank">Larsen and Toubro Infotech</a>
						<address>
							Mumbai,
							India</address>
						<details>
							<summary>Details</summary>
							<ul>
								<li>Established and engineered ETL processes using PySpark to ingest and transform large datasets across multiple platforms (local storage,
HDFS, Hive, and MySQL), improving data processing efficiency by 50% and supporting real-time analytics.</li>
								<li>Enhanced and optimized Apache Kafka and Spark Streaming for real-time data ingestion, enabling seamless integration and streaming
of large datasets, which enhanced system performance by 30% and ensured timely data availability.</li>
								<li>Executed data ingestion workflows across S3 and Hadoop environments, using PySpark to manage large datasets. This resulted in a
30% reduction in manual tasks and increased storage efficiency by 40% through compression and partitioning techniques.</li>
								<li>Created Tableau dashboards for business insights and presented clear visualizations to stakeholders, driving data-driven decisions.</li>
								
							
				</ul>
			</section>


			<section id="projects">
				<h2>Projects</h2>
				<ul>

					<li><strong>October 2024 &mdash; November 2024: </strong>Azure End-to-End Data Pipeline for Customer and Sales Insights</li>
					<details>
						<summary>Details</summary>
						<ul>
							<li>
								EBuilt a scalable data pipeline using Azure Data Factory and Databricks, automating data ingestion, transformation, and storage across
Bronze, Silver, and Gold layers in Azure Data Lake.
							</li>
							<li>Streamlined data processing in Azure Synapse Analytics, implementing partitioning and incremental loading to enhance query
performance and enable real-time reporting in Power BI.</li>
							
							
						</ul>
					</details>


					<li><strong>Feb 2024 &mdash; March 2024: </strong>Uber Data Analytics Pipeline Using Google Cloud Platform</li>
					<details>
						<summary>Details</summary>
						<ul>
							<li>
								Designed an end-to-end ETL pipeline on Google Cloud Platform (GCP) utilizing Google Storage for data ingestion, Mage for data
orchestration, and BigQuery for efficient data processing, enabling scalable analytics on Uber trip records.
							</li>
							<li>Restructured data transformation workflows using Python and SQL within Mage pipelines, ensuring data integrity and creating
structured datasets for visualization in Looker Studio, enhancing business insights and reporting efficiency.</li>
							
							
						</ul>
					</details>














					
					<li><strong>October 2023 &mdash; December 2023: </strong>Predective Modelling Of House Prices In Ames Dataset</li>
					<details>
						<summary>Details</summary>
						<ul>
							<li>
								Engineered an advanced housing price prediction model using the Ames Housing dataset, employing Linear models and random Forest.
							</li>
							<li>Produced a 15% accuracy boost through innovative feature engineering and model optimization techniques.</li>
							<li>Applied Box-Cox and square root transformations to tackle non-constant variance issues.</li>
							<li>Showcased expertise in advanced statistical methodologies, enhancing predictive modeling performance for the Ames Dataset.</li>
							
						</ul>
					</details>
					<li><strong>June 2023 &mdash; August 2023 : </strong>Covid-19 Analytics</li>
					<details>
						<summary>Details</summary>
						<ul>
							<li>
								Utilized PySpark to streamline healthcare datasets, converting unstructured data into a structured format for better accessibility.
							</li>
							<li>Merged data from various sources and formats, enhancing analysis capabilities in healthcare.</li>
							<li>Implemented a range of Spark transformations, significantly improving data processing efficiency.</li>
							<li>Assessed a 40% reduction in data processing time, facilitating real-time analytics in the healthcare sector.</li>
							
						</ul>
					</details>
					<li><strong>January 2022 &mdash; May 2022 : </strong>Social Distancing And Face Mask Detection For Covid Prevention</li>
					<details>
						<summary>Details</summary>
						<ul>
							<li>
								Created a machine learning system for monitoring social distancing and mask use, boosting compliance by 40% across locations..
							</li>
							<li>Exercised live feeds and recorded data to assess public health measures effectively, ensuring adherence to safety protocols.</li>
							<li>Improved object detection by enhancing MobileNetV2 and YOLO libraries with Python and OpenCV, focusing on public health.</li>
							<li>Analysed high precision and real-time data processing, critical for maintaining public health and safety standards.</li>
							
						</ul>
					</details>
					<li><strong>August 2021  &mdash; December 2021: </strong>Chatbot For HealthCare</li>
					<details>
						<summary>Details</summary>
						<ul>
							<li>Designed a healthcare web app with a chatbot, leveraging NLP, data collection, and user authentication to enhance medical access.</li>
							<li>Utilized intent/entity recognition to streamline patient interactions, significantly reducing unnecessary hospital visits by 40%.</li>
							<li>Improved patient satisfaction through better access and privacy, leading to enhanced healthcare experiences.</li>
						</ul>
					
				</ul>
			</section>

			<section id="skills&certifications">  
				<h2>Skills and Certifications</h2>
				<ul>
            <li><strong>Programming Languages:</strong> üêç Python, üõ¢Ô∏è SQL, ‚òï Java, üìò R, üñ•Ô∏è C, C++</li>
            <li><strong>Tools & Platforms:</strong> üêò Hadoop, üîÑ PySpark, üåü Apache Airflow, ‚òÅÔ∏è Databricks, 
                üîó Hive, Kafka, üìä Tableau, Power BI, AWS QuickSight</li>
            <li><strong>Cloud Platforms:</strong> ‚òÅÔ∏è AWS, GCP</li>
            <li><strong>Data Management:</strong> üìÇ ETL/ELT, üõ¢Ô∏è Data Warehousing, üì¶ Data Lake Integration, 
                üîó Redshift</li>
            <li><strong>Big Data Architecture:</strong> Scalable data processing and real-time ingestion 
                with Kafka and Spark Streaming</li>
            <li><strong>Certifications:</strong> üèÖ Databricks Certified Developer for Apache Spark 3.0</li>
        </ul>
			</section>

			<section id="developments">
				<h2>Developments</h2>
				<ul>
					<li><strong>Oct 2024: </strong> Started Working as a Data Engineering Intern at <a href="https://www.consultevergreen.com/"
							target="_blank">Evergreen Solutions</a>.</li>
					<li><strong>July 2024: </strong> Started Working as a Research Intern in Data Engineering at Florida State University
					</li>
					<li><strong class="accept">December 2023: </strong> Started working as a Student Lead Supervisor for 70 people at Aramark.</li>
					<li><strong>August 2023: </strong>Started M.S. in Data Science at <a href="https://www.fsu.edu/"
							target="_blank">Florida State University</a>.</li>
					<li><strong class="accept">August 2022: </strong> Promoted to Senior data engineer  at <a
							href="https://www.ltimindtree.com/" target="_blank">LTIMindtree.</a> </li>
					
					<li><strong class="accept">June 2022: </strong> Started working as a data engineer  at <a
							href="https://www.ltimindtree.com/" target="_blank">LTIMindtree.</a> </li>
					<li><strong class="accpet">May 2022: </strong>Graduated with a B.Tech in Computer Science and
						Engineering from <a href="https://srmist.edu.in">SRM Institute of Science and
							Technology</a>.</li>
					<li><strong>April 2022: </strong> One paper accepted at <a href="https://ijsrem.com/"
							target="_blank">IJSREM</a>.</li>
					

				</ul>
			</section>

			<section id="contact">
				<h2>Contact</h2>
				<p>You can also schedule a 1-on-1 meeting with me using the following <a
						href="https://calendly.com/snaratipamula/30min" target="_blank" rel="noopener noreferrer">link</a>.
				</p>
				<p><span class="fas fa-envelope"></span>: <a href="mailto:snaratipamula@gmail.com"
						target="_blank">snaratipamula@gmail.com</a></p>
				<p><span class="fab fa-linkedin-in"></span>: <a href="https://www.linkedin.com/in/sainikhilaratipamula/"
						target="_blank">in/Sai Nikhil Aratipamula/</a></p>
				<p><span class="fab fa-github"></span>: <a href="https://github.com/SaiNikhilAratipamula"
						target="_blank">/SaiNikhilAratipamula</a>
				</p>
				<p><span class="fas fa-phone"></span>: <a href="tel:+18503393663" target="_blank">+1 (850) 339-3663</a>
				</p>
			</section>

		</div>
		
	</main>
</body>

</html>
